{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d68df2bd",
   "metadata": {},
   "source": [
    "## Advanced Regression Assignment (Housing data analysis)\n",
    "\n",
    "\n",
    "### Reading and Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b843cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the required libraries\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19eb90c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4606e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b25ac24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data-info and other info regarding the null data\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2519141",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "- \n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "017a6e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "136acd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_data_columns = data.columns[data.isna().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de67408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pprint import pprint\n",
    "for c in null_data_columns:\n",
    "    print(c, data[c].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0293caa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_null_percentage = data.apply(lambda x: round(x.isnull().mean()* 100, 2))\n",
    "data_null_percentage[data_null_percentage>0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70e6c619",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_null_above_thresold = data_null_percentage[data_null_percentage>40.0]\n",
    "null_above_thresold_columns = data_null_above_thresold.index\n",
    "f\"{len(null_above_thresold_columns)} columns out of {len(data.columns)} columns to be dropped from the dataframe data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9be34272",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(null_above_thresold_columns, axis=1, inplace= True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05b6de1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets understand the behaviour of some categorical data\n",
    "\n",
    "fig=data.plot.box(title='Outliers', figsize=(80, 40), legend=True, fontsize=24)\n",
    "fig.axes.title.set_size(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b48bd0",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- The plot shows that the column with the most variation and outliers is the dependant variable, SalePrice. LotArea has also some outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d02b4ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [feature for feature in data.columns if data[feature].dtypes!='object']\n",
    "for feature in numerical_features:\n",
    "    if feature=='class(target)':\n",
    "        pass\n",
    "    else:\n",
    "        sns.histplot(x=feature, data=data)\n",
    "        plt.xlabel(feature)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83adee93",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- The histograms above describe the skewness of the data. They also suggest that `LowQualFinSF`, `PoolArea`, `MiscVal`, and `3SsnPorch` contain very little variety in values.\n",
    "</br>\n",
    "\n",
    "- From a business logic standpoint, `PoolArea` is a similar variable to the previously dropped one. This is also the case for `MiscVal` - in additon, it has a rather high number of outliers. `3SsnPorchappears` to be contained in the other porch values. They are dropped as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30fa0b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop above features\n",
    "\n",
    "data = data.drop(['LowQualFinSF', 'PoolArea', 'MiscVal', '3SsnPorch'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9cee856",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560cbf9b",
   "metadata": {},
   "source": [
    "## Missing value treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ea53ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check for the missing value\n",
    "\n",
    "def get_missing_counts(data: pd.DataFrame, columns: list):\n",
    "    for column in columns:\n",
    "        print(column, data[column].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f313c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_missing_data =  data.columns[data.isnull().any()]\n",
    "\n",
    "get_missing_counts(data=data,\n",
    "                   columns=columns_with_missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95e85501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing the values with median\n",
    "\n",
    "data['LotFrontage'] = data['LotFrontage'].fillna(data['LotFrontage'].median())\n",
    "data['GarageYrBlt'] = data['GarageYrBlt'].fillna(data['GarageYrBlt'].median())\n",
    "data['MasVnrArea'] = data['MasVnrArea'].fillna(data['MasVnrArea'].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8c4f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing the values with mode\n",
    "\n",
    "for column in ['GarageCond', 'GarageType', 'GarageFinish','GarageQual','BsmtExposure', 'BsmtFinType2', 'BsmtFinType1','BsmtCond','BsmtQual', 'Electrical']:\n",
    "    \n",
    "    data[column] = data[column].fillna(data[column].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e95fab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ce54ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a28fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35d7c021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5915f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(house[cols] < (Q1 - 1.5 * IQR)) |(house[cols] > (Q3 + 1.5 * IQR))).any("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762c67f1",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91f28b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab462d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop `Id`as it has no significance further in the dataset\n",
    "data = data.drop(['Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b72156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ea6a08",
   "metadata": {},
   "source": [
    "## Visualising the Data\n",
    "\n",
    "Let's now spend some time doing what is arguably the most important step - **understanding the data**.\n",
    "- If there is some obvious multicollinearity going on, this is the first place to catch it\n",
    "- Here's where you'll also identify if some predictors directly have a strong association with the outcome variable\n",
    "\n",
    "We'll visualise our data using `matplotlib` and `seaborn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "523e6938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see pair plot to understand the behaviour of one feature w.r.t to other feature\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.pairplot(data, x_vars=['MSSubClass','LotFrontage','LotArea'], y_vars='SalePrice',height=4, aspect=1,kind='scatter')\n",
    "sns.pairplot(data, x_vars=['OverallQual', 'OverallCond','MasVnrArea'], y_vars='SalePrice',height=4, aspect=1,kind='scatter')\n",
    "sns.pairplot(data, x_vars=['BsmtFinSF1', 'BsmtUnfSF','TotalBsmtSF'], y_vars='SalePrice',height=4, aspect=1,kind='scatter')\n",
    "sns.pairplot(data, x_vars=['1stFlrSF','2ndFlrSF', 'GrLivArea'], y_vars='SalePrice',height=4, aspect=1,kind='scatter')\n",
    "sns.pairplot(data, x_vars=['BsmtFullBath','FullBath', 'HalfBath'], y_vars='SalePrice',height=4, aspect=1,kind='scatter')\n",
    "sns.pairplot(data, x_vars=['BedroomAbvGr','TotRmsAbvGrd', 'Fireplaces'], y_vars='SalePrice',height=4, aspect=1,kind='scatter')\n",
    "sns.pairplot(data, x_vars=['GarageCars','GarageArea', 'WoodDeckSF'], y_vars='SalePrice',height=4, aspect=1,kind='scatter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07d2e16",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "- The above pair plots shows that the features like `GarageArea`, `1stFlrSF` and `GrLivArea` show very good correlation with the `SalePrice`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5896fd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all numeric (float and int) variables in the dataset\n",
    "data_numeric = data.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "#Finding correlation matric\n",
    "corr_matrix = data_numeric.corr()\n",
    "plt.figure(figsize=(20,20))\n",
    "#plotting correlatioon matric on a heat map\n",
    "ax = sns.heatmap(corr_matrix, annot = True, cmap='BuPu_r')\n",
    "top, bottom = ax.get_ylim()\n",
    "ax.set_ylim(top+0.5, bottom-0.5)\n",
    "plt.title(\"Correlation between Columns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47df75a",
   "metadata": {},
   "source": [
    "## Dropping multi-colinear data\n",
    "\n",
    "Insights from the heatmap: Correlation of sale price with independent variables:\n",
    "\n",
    "- Sale price is highly positively correlated with OverallQual, GrLivArea\n",
    "- Sale price is positively correlated with `TotalBsmtSF`, `1stFlrSF`, `FullBath`, `TotRmsAbvGrd`, `GarageCars`, `GarageArea`\n",
    "- `Sale price` is not highly negatively correlated with other variables.\n",
    "\n",
    "</br>\n",
    "Some independent variables are highly correlated with each other. This has to be considered because of multicollinearity that may become an issue in the model.\n",
    "\n",
    "- `Yearbuilt`, `GarageYrBlt` -> highly correlated\n",
    "- `TotRmsAbvGrd`, `GrLivArea`-> highly correlated\n",
    "- `GarageArea` ,`GarageCars` -> highly correlated\n",
    "- `1stFlrSF`, `TotalBsmtSF` -> highly correlated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50a3c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop highly correlated features\n",
    "\n",
    "data.drop(['1stFlrSF','TotRmsAbvGrd','GarageArea', 'GarageYrBlt'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3be7b7d",
   "metadata": {},
   "source": [
    "## Create Dummy variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbec176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to get the dummy variable dataframe\n",
    "\n",
    "def get_dummy_dataframe(column_name: list[str]):\n",
    "    output = pd.DataFrame()\n",
    "    for column in column_name:\n",
    "        status = pd.get_dummies(data[column], drop_first=True)\n",
    "        output = pd.concat([output, status], axis=1)  # Concatenate the status DataFrame to the output\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79e69a77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check which columns containg categorical data\n",
    "data_categorical = data.select_dtypes(include=['object'])\n",
    "data_categorical.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f8434e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a950d9c",
   "metadata": {},
   "source": [
    "## Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df196ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop categorical variables from the dataset and save as predictor variable X\n",
    "X= data.drop(list(data_categorical.columns), axis=1)\n",
    "X=X.drop(['SalePrice'], axis=1)\n",
    "y = data['SalePrice']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4a38418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "cols = X.columns\n",
    "X = pd.DataFrame(scale(X))\n",
    "X.columns = cols\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e25ac47",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52ba5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "X_train, X_test, y_train,  y_test = train_test_split(X, y, \n",
    "                                                    train_size=0.70,\n",
    "                                                    test_size = 0.30, random_state=42)\n",
    "\n",
    "# Instantiate linear regression\n",
    "lm = LinearRegression()\n",
    "\n",
    "# Fit a line\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "044af502",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "\n",
    "# Fit a line\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1648fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm.intercept_)\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95cbc10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = lm.predict(X_train)\n",
    "y_pred_test = lm.predict(X_test)\n",
    "\n",
    "metric = []\n",
    "r2_train_lr = r2_score(y_train, y_pred_train)\n",
    "print('r2 train: ', r2_train_lr)\n",
    "metric.append(r2_train_lr)\n",
    "\n",
    "r2_test_lr = r2_score(y_test, y_pred_test)\n",
    "print('r2 test: ',r2_test_lr)\n",
    "metric.append(r2_test_lr)\n",
    "\n",
    "rss1_lr = np.sum(np.square(y_train - y_pred_train))\n",
    "print('rss1: ',rss1_lr)\n",
    "metric.append(rss1_lr)\n",
    "\n",
    "rss2_lr = np.sum(np.square(y_test - y_pred_test))\n",
    "print('rss2: ',rss2_lr)\n",
    "metric.append(rss2_lr)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_train, y_pred_train)\n",
    "print('MSE train: ',mse_train_lr)\n",
    "metric.append(mse_train_lr**0.5)\n",
    "\n",
    "mse_test_lr = mean_squared_error(y_test, y_pred_test)\n",
    "print('MSE test: ',mse_test_lr)\n",
    "metric.append(mse_test_lr**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d68f2f",
   "metadata": {},
   "source": [
    "## Ridge and Lasso implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b1a65c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n",
    "\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "# cross validation\n",
    "folds = 4\n",
    "ridge_model_cv = GridSearchCV(estimator = ridge, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = folds, \n",
    "                        return_train_score=True,\n",
    "                        verbose = 1)            \n",
    "ridge_model_cv.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0fec58d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the best hyperparameter alpha\n",
    "print(ridge_model_cv.best_params_)\n",
    "print(ridge_model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5fc9a1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 100\n",
    "ridge = Ridge(alpha=alpha)\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61f51f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets calculate some metrics such as R2 score, RSS and RMSE\n",
    "y_pred_train = ridge.predict(X_train)\n",
    "y_pred_test = ridge.predict(X_test)\n",
    "\n",
    "metric2 = []\n",
    "r2_train_lr = r2_score(y_train, y_pred_train)\n",
    "print(r2_train_lr)\n",
    "metric2.append(r2_train_lr)\n",
    "\n",
    "r2_test_lr = r2_score(y_test, y_pred_test)\n",
    "print(r2_test_lr)\n",
    "metric2.append(r2_test_lr)\n",
    "\n",
    "rss1_lr = np.sum(np.square(y_train - y_pred_train))\n",
    "print(rss1_lr)\n",
    "metric2.append(rss1_lr)\n",
    "\n",
    "rss2_lr = np.sum(np.square(y_test - y_pred_test))\n",
    "print(rss2_lr)\n",
    "metric2.append(rss2_lr)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_train, y_pred_train)\n",
    "print(mse_train_lr)\n",
    "metric2.append(mse_train_lr**0.5)\n",
    "\n",
    "mse_test_lr = mean_squared_error(y_test, y_pred_test)\n",
    "print(mse_test_lr)\n",
    "metric2.append(mse_test_lr**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "125fe67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lasso Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80422e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "\n",
    "# cross validation\n",
    "lasso_model_cv = GridSearchCV(estimator = lasso, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = folds, \n",
    "                        return_train_score=True,\n",
    "                        verbose = 1)            \n",
    "\n",
    "lasso_model_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3b634e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lasso_model_cv.best_params_)\n",
    "print(lasso_model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6369f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lpha =0.001\n",
    "\n",
    "lasso = Lasso(alpha=alpha)\n",
    "        \n",
    "lasso.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95ca66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "557f87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = X_train.columns\n",
    "\n",
    "coef = pd.Series(lasso.coef_,predictors).sort_values()\n",
    "\n",
    "coef.plot(kind='bar', title='Modal Coefficients', fontsize='16',figsize=(80, 60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47359340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets calculate some metrics such as R2 score, RSS and RMSE\n",
    "\n",
    "y_pred_train = lasso.predict(X_train)\n",
    "y_pred_test = lasso.predict(X_test)\n",
    "\n",
    "metric3 = []\n",
    "r2_train_lr = r2_score(y_train, y_pred_train)\n",
    "print(r2_train_lr)\n",
    "metric3.append(r2_train_lr)\n",
    "\n",
    "r2_test_lr = r2_score(y_test, y_pred_test)\n",
    "print(r2_test_lr)\n",
    "metric3.append(r2_test_lr)\n",
    "\n",
    "rss1_lr = np.sum(np.square(y_train - y_pred_train))\n",
    "print(rss1_lr)\n",
    "metric3.append(rss1_lr)\n",
    "\n",
    "rss2_lr = np.sum(np.square(y_test - y_pred_test))\n",
    "print(rss2_lr)\n",
    "metric3.append(rss2_lr)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_train, y_pred_train)\n",
    "print(mse_train_lr)\n",
    "metric3.append(mse_train_lr**0.5)\n",
    "\n",
    "mse_test_lr = mean_squared_error(y_test, y_pred_test)\n",
    "print(mse_test_lr)\n",
    "metric3.append(mse_test_lr**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8dda1c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a table which contain all the metrics\n",
    "\n",
    "lr_table = {'Metric': ['R2 Score (Train)','R2 Score (Test)','RSS (Train)','RSS (Test)',\n",
    "                       'MSE (Train)','MSE (Test)'], \n",
    "        'Linear Regression': metric\n",
    "        }\n",
    "\n",
    "lr_metric = pd.DataFrame(lr_table ,columns = ['Metric', 'Linear Regression'] )\n",
    "\n",
    "rg_metric = pd.Series(metric2, name = 'Ridge Regression')\n",
    "ls_metric = pd.Series(metric3, name = 'Lasso Regression')\n",
    "\n",
    "final_metric = pd.concat([lr_metric, rg_metric, ls_metric], axis = 1)\n",
    "\n",
    "final_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5fbe44",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df67ddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pred = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8d839d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting y_test and y_pred to understand the spread for ridge regression.\n",
    "fig = plt.figure(dpi=100)\n",
    "plt.scatter(y_test,ridge_pred)\n",
    "fig.suptitle('y_test vs ridge_pred', fontsize=20)              # Plot heading \n",
    "plt.xlabel('y_test', fontsize=18)                          # X-label\n",
    "plt.ylabel('ridge_pred', fontsize=16)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d747f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res=y_test-ridge_pred\n",
    "# Distribution of errors\n",
    "sns.distplot(y_res,kde=True)\n",
    "plt.title('Normality of error terms/residuals Ridge')\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dfb46a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_pred = lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d82bb245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting y_test and y_pred to understand the spread for lasso regression.\n",
    "fig = plt.figure(dpi=100)\n",
    "plt.scatter(y_test,lasso_pred)\n",
    "fig.suptitle('y_test vs lasso_pred', fontsize=20)              # Plot heading \n",
    "plt.xlabel('y_test', fontsize=18)                          # X-label\n",
    "plt.ylabel('lasso_pred', fontsize=16)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7ea4e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res=y_test-lasso_pred\n",
    "# Distribution of errors\n",
    "sns.distplot(y_res,kde=True)\n",
    "plt.title('Normality of error terms/residuals Lasso')\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17659b0",
   "metadata": {},
   "source": [
    "## Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "22c6b162",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = pd.DataFrame(index=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8a623e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas.rows = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c873109",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas['Linear'] = lm.coef_\n",
    "betas['Ridge'] = ridge.coef_\n",
    "betas['Lasso'] = lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d86ac6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas.head(68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7529d922",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = pd.DataFrame(index=X_train.columns)\n",
    "betas.rows = X_train.columns\n",
    "betas['Lasso'] = lasso.coef_\n",
    "betas.sort_values(by=['Lasso'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4421d901",
   "metadata": {},
   "source": [
    "## Evalution of the model\n",
    "\n",
    "The model shows that there are some variables that are highly relevant to the sales price. Suggestions for Surprise Housing is to keep a check on these predictors affecting the price of the house. The higher values of positive coeeficients suggest a high sale value. Some of those features are:\n",
    "\n",
    "Feature\tDescription\n",
    "`GrLivArea`\tAbove grade (ground) living area square feet\n",
    "`OverallQual`\tRates the overall material and finish of the house\n",
    "`OverallCond`\tRates the overall condition of the house\n",
    "`TotalBsmtSF`\tTotal square feet of basement area\n",
    "`GarageArea`\tSize of garage in square feet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
